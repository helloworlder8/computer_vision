

# Ultralytics YOLO üöÄ, AGPL-3.0 license
# YOLOv8 object detection model with P3-P5 outputs. For Usage examples see https://docs.ultralytics.com/tasks/detect

# Parameters
nc: 80 # number of classes
scales: # model compound scaling constants, i.e. 'model=yolov8n.yaml' will call yolov8.yaml with scale 'n'
  # [depth, width, max_channels]
  # n: [1, 1, 1024] # YOLOv8n summary: 225 layers,  3157200 parameters,  3157184 gradients,   8.9 GFLOPs
  n: [0.33, 0.167, 1024] # YOLOv8n summary: 225 layers,  3157200 parameters,  3157184 gradients,   8.9 GFLOPs
  s: [0.33, 0.217, 1024] # YOLOv8n summary: 225 layers,  3157200 parameters,  3157184 gradients,   8.9 GFLOPs
  m: [0.33, 0.25, 1024] # YOLOv8n summary: 225 layers,  3157200 parameters,  3157184 gradients,   8.9 GFLOPs
  l: [1.00, 1.00, 512] # YOLOv8l summary: 365 layers, 43691520 parameters, 43691504 gradients, 165.7 GFLOPs
  x: [1.00, 1.25, 512] # YOLOv8x summary: 365 layers, 68229648 parameters, 68229632 gradients, 258.5 GFLOPs

# YOLOv8.0n backbone
backbone:  
# def __init__(self, C_in, C_out, num_blocks=1, alpha=0.2, beta=1, stride=1, use_identity=False, shortcut_mode=False):
  - [-1, 1, Conv, [32, 3, 2]] #     32 320 320                         0
  - [-1, 1, Conv, [64, 3, 2]] #     64 160 160                         1
  - [-1, 1, Conv, [64, 3, 1]] #     64 160 160                         2
  - [-1, 1, Conv, [128, 3, 1]] #    128 160 160                        3
  - [-1, 1, ALSS, [128, 0.4, 0.4, 2, True, 0]] #    128 80 80          4 Ê≠•Èïø‰∏∫2ÁöÑÊÉÖÂÜµÂÜçËÄÉËôëshortcut_mode
  - [-1, 1, ALSS, [256, 0.4, 0.4, 1, False,-1 ]] #  256 80 80          5 Êãº
  - [-1, 1, ALSS, [512, 0.5, 0.5, 2, True, 1]] #    512 40 40          6 
  - [-1, 1, ALSS, [512, 0.6, 0.6, 1, False,-1]] #   512 40 40      64  7 Êãº
  - [-1, 1, ALSS, [1024,0.7, 0.6, 2, True, 2]] #    1024 20 20         8
  - [-1, 1, SPPF, [1024, 5]]                  #     1024 20 20         9 Êãº

# YOLOv8.0n head
head:
  - [-1, 1, nn.Upsample, [None, 2, "nearest"]] #1024 40 40             10
  - [[-1, 7], 1, Concat, [1]]                  #1536 40 40             11
  - [-1, 1, ALSS, [512, 0.2, 0.8, 1, True, -1]] #512 40 40             12 Êãº
  - [-1, 1, nn.Upsample, [None, 2, "nearest"]]  #512 80 80             13
  - [[-1, 5], 1, Concat, [1]] # cat backbone P3  768 80 80             14

  - [-1, 1, MSCAMv3, [4]]                                  # 15 


  - [-1, 1, ALSS, [256, 0.2, 0.8, 1, True, -1]] #  256 80 80           16 Âá∫
  - [-1, 1, Conv, [256, 3, 2]] #                   256 40 40           17
  - [[-1,12], 1, Concat, [1]]  #                   768 40 40           18
  - [-1, 1, ALSS, [512, 0.4, 0.8, 1, True, -1]] #  512 40 40           19 Âá∫
  - [-1, 1, Conv, [512, 3, 2]] #                   512 20 20           20
  - [[-1, 9], 1, Concat, [1]]                     #1536 20 20          21  
  - [-1, 1, ALSS, [1024, 0.6, 0.8, 1, True, -1]] # 1024 20 20          22 Âá∫
# MSCAM


  # - [[15, 19, 23], 1, Detect, [nc]] # Detect(P3, P4, P5)               24
  - [[16, 19, 22], 1, Segment, [nc, 32, 256, 24]] # Detect(P3, P4, P5) 
# nc=80, nm=32, npr=256

# Model summary: 268 layers, 1,824,473 parameters, 1,824,449 gradients, 9.4 GFLOPs
# Model summary (fused): 208 layers, 1,822,717 parameters, 1,822,693 gradients, 9.3 GFLOPs